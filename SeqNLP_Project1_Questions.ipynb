{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SeqNLP_Project1_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "outputId": "99e4c41b-badf-4a55-8657-d1bb324e24e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fCPC_WN-eCyw",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qMEsHYrWxdtk"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0g381XzeCyz",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jy6n-uM2eCy2",
        "outputId": "ac4ff331-e227-44e5-9679-1a955ec812ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(x_train), len(x_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZhMAgaNeCy5",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dybtUgUReCy8"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5OLM4eBeCy9",
        "outputId": "576964fa-8817-4545-d72a-2c37fd971fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in x_train[6]])\n",
        "\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 1us/step\n",
            "---review with words---\n",
            "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'the', 'boiled', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'murdering', 'naschy', 'br', 'villain', 'and', 'suggestion', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxNDNhrseCzA",
        "outputId": "38347449-e1c0-4455-937d-ff352973b950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "embedding_vector_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_vector_length, input_length=maxlen))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               8448      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 337,025\n",
            "Trainable params: 337,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3CSVVPPeCzD",
        "outputId": "f7db2597-8622-4e2b-a663-b96a1be5964f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "\n",
        "x_valid, y_valid = x_train[:batch_size], y_train[:batch_size]\n",
        "x_train_, y_train_ = x_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "\n",
        "train_history = model.fit(x_train_, y_train_, \n",
        "                          validation_data=(x_valid, y_valid), \n",
        "                          batch_size=batch_size, \n",
        "                          epochs=num_epochs, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 24936 samples, validate on 64 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 242s - loss: 0.4014 - acc: 0.8113 - val_loss: 0.2321 - val_acc: 0.9219\n",
            "Epoch 2/10\n",
            " - 234s - loss: 0.2335 - acc: 0.9098 - val_loss: 0.1874 - val_acc: 0.9219\n",
            "Epoch 3/10\n",
            " - 233s - loss: 0.1783 - acc: 0.9329 - val_loss: 0.2470 - val_acc: 0.9062\n",
            "Epoch 4/10\n",
            " - 233s - loss: 0.1397 - acc: 0.9482 - val_loss: 0.3034 - val_acc: 0.8906\n",
            "Epoch 5/10\n",
            " - 231s - loss: 0.1043 - acc: 0.9630 - val_loss: 0.3268 - val_acc: 0.8906\n",
            "Epoch 6/10\n",
            " - 233s - loss: 0.0891 - acc: 0.9677 - val_loss: 0.4405 - val_acc: 0.8750\n",
            "Epoch 7/10\n",
            " - 235s - loss: 0.0719 - acc: 0.9741 - val_loss: 0.4734 - val_acc: 0.8750\n",
            "Epoch 8/10\n",
            " - 233s - loss: 0.0580 - acc: 0.9806 - val_loss: 0.6597 - val_acc: 0.8906\n",
            "Epoch 9/10\n",
            " - 235s - loss: 0.0548 - acc: 0.9813 - val_loss: 0.4783 - val_acc: 0.8906\n",
            "Epoch 10/10\n",
            " - 232s - loss: 0.0465 - acc: 0.9853 - val_loss: 0.5750 - val_acc: 0.9062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi11mxMck3gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_train_history(train_history,train,validation):\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Train History')\n",
        "    plt.ylabel(train)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9MPkWBuk7lX",
        "colab_type": "code",
        "outputId": "87cbf269-659f-465a-c12f-24f26da2d55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "show_train_history(train_history,'acc','val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ9CPKIGlA6W",
        "colab_type": "code",
        "outputId": "d7185c99-f1d3-4dd0-928e-ba772a5d8539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluate model by test set\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# Predict test data\n",
        "predict=model.predict_classes(x_test)\n",
        "predict_classes=predict.reshape(len(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igq8Qm8GeCzG"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0AqOnLa2eCzH",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-dUDSg7VeCzM",
        "outputId": "1ba35a39-75c3-4f68-e61f-c34e07eeabe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inp = model.input                                           # input placeholder\n",
        "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
        "\n",
        "# Testing\n",
        "#test = np.random.random(input_shape)[np.newaxis,...]\n",
        "test_sample = x_test[0].reshape(1,-1)\n",
        "layer_outs = [func([test_sample, 1.]) for func in functors]\n",
        "\n",
        "for index, layer in enumerate(layer_outs):\n",
        "    print(f'\\nOutput of layer {index}, shape {np.array(layer_outs[index]).shape}  ------>')\n",
        "    print(layer_outs[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Output of layer 0, shape (1, 1, 300, 32)  ------>\n",
            "[array([[[-0.04999315,  0.00551191,  0.06298603, ..., -0.03516566,\n",
            "         -0.01786362,  0.0098074 ],\n",
            "        [-0.04999315,  0.00551191,  0.06298603, ..., -0.03516566,\n",
            "         -0.01786362,  0.0098074 ],\n",
            "        [-0.04999315,  0.00551191,  0.06298603, ..., -0.03516566,\n",
            "         -0.01786362,  0.0098074 ],\n",
            "        ...,\n",
            "        [ 0.02320201,  0.00728727,  0.05734314, ..., -0.00841749,\n",
            "         -0.02756022,  0.03565748],\n",
            "        [-0.03787236,  0.01771588, -0.01316862, ...,  0.00106458,\n",
            "          0.02452109, -0.01197266],\n",
            "        [ 0.13999961, -0.13356502, -0.00820625, ..., -0.03694197,\n",
            "         -0.0055538 , -0.07904448]]], dtype=float32)]\n",
            "\n",
            "Output of layer 1, shape (1, 1, 300, 32)  ------>\n",
            "[array([[[-0.06249144,  0.00688989,  0.07873254, ..., -0.04395708,\n",
            "         -0.02232952,  0.01225925],\n",
            "        [-0.        ,  0.00688989,  0.07873254, ..., -0.04395708,\n",
            "         -0.02232952,  0.01225925],\n",
            "        [-0.06249144,  0.00688989,  0.07873254, ..., -0.04395708,\n",
            "         -0.02232952,  0.01225925],\n",
            "        ...,\n",
            "        [ 0.02900251,  0.00910909,  0.        , ..., -0.        ,\n",
            "         -0.03445028,  0.04457185],\n",
            "        [-0.04734045,  0.        , -0.01646078, ...,  0.00133072,\n",
            "          0.03065136, -0.01496582],\n",
            "        [ 0.17499952, -0.16695628, -0.01025782, ..., -0.04617746,\n",
            "         -0.00694225, -0.09880561]]], dtype=float32)]\n",
            "\n",
            "Output of layer 2, shape (1, 1, 32)  ------>\n",
            "[array([[ 0.07738795, -0.05357408,  0.01978577, -0.02460335,  0.00358758,\n",
            "         0.01451114,  0.02193305, -0.10885422,  0.01596281, -0.02192301,\n",
            "        -0.00168324, -0.04926995,  0.14038205,  0.0281694 , -0.00030721,\n",
            "         0.1024529 ,  0.01516641, -0.01393482, -0.02748196, -0.09049492,\n",
            "         0.03026391,  0.13907994,  0.00679418,  0.08617504, -0.08522747,\n",
            "        -0.0640737 ,  0.06725467,  0.04212065, -0.03343086,  0.00186275,\n",
            "        -0.01345978,  0.02492442]], dtype=float32)]\n",
            "\n",
            "Output of layer 3, shape (1, 1, 256)  ------>\n",
            "[array([[0.        , 0.        , 0.        , 0.12751584, 0.09895997,\n",
            "        0.13045378, 0.        , 0.15849607, 0.        , 0.11011216,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.18723829, 0.        , 0.        , 0.14188686, 0.        ,\n",
            "        0.18743882, 0.02097137, 0.        , 0.1368894 , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.18347126, 0.08212957,\n",
            "        0.16122329, 0.        , 0.        , 0.13852662, 0.14652906,\n",
            "        0.14637819, 0.        , 0.04875337, 0.12177265, 0.        ,\n",
            "        0.        , 0.09296053, 0.1050217 , 0.1423972 , 0.        ,\n",
            "        0.15744083, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.20350167, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.22024876, 0.11409532, 0.        , 0.        , 0.15740457,\n",
            "        0.        , 0.        , 0.09224743, 0.16755569, 0.09912491,\n",
            "        0.14680767, 0.18134102, 0.        , 0.17238417, 0.00526327,\n",
            "        0.        , 0.        , 0.09204804, 0.17979747, 0.08782618,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.17846772, 0.        , 0.13189632, 0.        , 0.20517257,\n",
            "        0.        , 0.14654395, 0.11225521, 0.        , 0.1327295 ,\n",
            "        0.        , 0.17286777, 0.        , 0.        , 0.1401689 ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.09423102, 0.        , 0.        , 0.10241218,\n",
            "        0.0069926 , 0.        , 0.10836419, 0.        , 0.1830844 ,\n",
            "        0.        , 0.1371654 , 0.        , 0.1875462 , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.09619118,\n",
            "        0.        , 0.        , 0.14916731, 0.17753944, 0.        ,\n",
            "        0.07281129, 0.19657908, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.08278372, 0.14698079, 0.0348984 , 0.02336671,\n",
            "        0.12851948, 0.        , 0.        , 0.10271953, 0.164344  ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.10937321, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.05295154, 0.        ,\n",
            "        0.14971495, 0.        , 0.10038739, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.15734527, 0.        , 0.        ,\n",
            "        0.12471229, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.07873438, 0.        , 0.        , 0.17773391,\n",
            "        0.        , 0.        , 0.        , 0.12761913, 0.04625484,\n",
            "        0.17774385, 0.12039774, 0.        , 0.1758222 , 0.        ,\n",
            "        0.10832199, 0.1281869 , 0.        , 0.12407024, 0.04890215,\n",
            "        0.        , 0.14909807, 0.        , 0.        , 0.09916215,\n",
            "        0.        , 0.        , 0.15726818, 0.06540338, 0.07768565,\n",
            "        0.        , 0.        , 0.11420112, 0.12836729, 0.        ,\n",
            "        0.11780607, 0.        , 0.12532319, 0.        , 0.12959418,\n",
            "        0.08976556, 0.        , 0.11484537, 0.        , 0.00877064,\n",
            "        0.        , 0.        , 0.        , 0.15217465, 0.12228246,\n",
            "        0.        , 0.13920225, 0.        , 0.        , 0.11923809,\n",
            "        0.05313657, 0.09098265, 0.17181364, 0.        , 0.00088253,\n",
            "        0.14915979, 0.12923118, 0.18697192, 0.        , 0.12161577,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.1302764 , 0.14035885, 0.1523806 , 0.09108958,\n",
            "        0.12347812, 0.        , 0.03489644, 0.        , 0.        ,\n",
            "        0.16024572]], dtype=float32)]\n",
            "\n",
            "Output of layer 4, shape (1, 1, 256)  ------>\n",
            "[array([[0.07702289, 0.00594026, 0.01607697, 0.        , 0.0490959 ,\n",
            "        0.        , 0.        , 0.10027055, 0.        , 0.02438881,\n",
            "        0.        , 0.12095217, 0.        , 0.01609599, 0.06870829,\n",
            "        0.        , 0.10013966, 0.        , 0.        , 0.        ,\n",
            "        0.12976675, 0.        , 0.        , 0.08060096, 0.05390605,\n",
            "        0.09144596, 0.18759355, 0.        , 0.0657995 , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.1046617 , 0.01621183,\n",
            "        0.07931492, 0.        , 0.01071924, 0.08222227, 0.        ,\n",
            "        0.11233016, 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.00905276, 0.0667243 , 0.09812687, 0.        ,\n",
            "        0.08336945, 0.        , 0.        , 0.        , 0.03413442,\n",
            "        0.        , 0.0301754 , 0.1715641 , 0.09220304, 0.        ,\n",
            "        0.19580987, 0.02203789, 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.10475805, 0.05148126,\n",
            "        0.08729666, 0.        , 0.        , 0.09025058, 0.12542975,\n",
            "        0.        , 0.02001561, 0.05799165, 0.        , 0.03178339,\n",
            "        0.02569097, 0.14337404, 0.        , 0.        , 0.        ,\n",
            "        0.0943    , 0.        , 0.01889539, 0.        , 0.        ,\n",
            "        0.09181325, 0.        , 0.030593  , 0.03273943, 0.        ,\n",
            "        0.02737724, 0.08458664, 0.0550381 , 0.        , 0.        ,\n",
            "        0.07698636, 0.        , 0.        , 0.        , 0.08583373,\n",
            "        0.01899786, 0.04038937, 0.00059111, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.01093356, 0.        , 0.        ,\n",
            "        0.        , 0.07192566, 0.08019482, 0.11160105, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.        , 0.09102099, 0.08143295, 0.12452281, 0.        ,\n",
            "        0.        , 0.1113596 , 0.        , 0.04762727, 0.        ,\n",
            "        0.        , 0.01971872, 0.        , 0.        , 0.16139798,\n",
            "        0.        , 0.13608238, 0.06363478, 0.03179269, 0.12226471,\n",
            "        0.        , 0.05426262, 0.01608035, 0.        , 0.05599584,\n",
            "        0.        , 0.00556139, 0.        , 0.12594411, 0.        ,\n",
            "        0.        , 0.01015984, 0.08433969, 0.        , 0.05240278,\n",
            "        0.11556725, 0.        , 0.00466884, 0.01145062, 0.        ,\n",
            "        0.        , 0.        , 0.10026166, 0.02461926, 0.0197601 ,\n",
            "        0.04431382, 0.        , 0.        , 0.04893014, 0.        ,\n",
            "        0.        , 0.        , 0.        , 0.05720204, 0.10541473,\n",
            "        0.        , 0.        , 0.02435776, 0.1069472 , 0.        ,\n",
            "        0.        , 0.06446016, 0.05102817, 0.        , 0.        ,\n",
            "        0.04901215, 0.        , 0.04852821, 0.03726586, 0.        ,\n",
            "        0.        , 0.        , 0.04957549, 0.02445202, 0.00566595,\n",
            "        0.11719792, 0.11485913, 0.09462204, 0.        , 0.00225142,\n",
            "        0.        , 0.14781672, 0.01220828, 0.04062037, 0.07580389,\n",
            "        0.04994882, 0.        , 0.04012387, 0.        , 0.        ,\n",
            "        0.        , 0.        , 0.03882754, 0.        , 0.06614545,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.03474939,\n",
            "        0.        , 0.07919873, 0.10712252, 0.        , 0.07480371,\n",
            "        0.        , 0.        , 0.08683648, 0.        , 0.12714623,\n",
            "        0.0809657 , 0.03275795, 0.14918385, 0.10436068, 0.03574298,\n",
            "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "        0.04111848, 0.00405864, 0.07927586, 0.07375856, 0.        ,\n",
            "        0.01985972, 0.06160777, 0.20244555, 0.        , 0.        ,\n",
            "        0.06529159]], dtype=float32)]\n",
            "\n",
            "Output of layer 5, shape (1, 1, 1)  ------>\n",
            "[array([[0.09030364]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tskt_1npeCzP",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}