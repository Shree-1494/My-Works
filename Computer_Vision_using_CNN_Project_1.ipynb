{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhhTcg9H9u9t"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgPq7Ami-etf"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Is6m5ICN_IMP"
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets list\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "hkymNY4v_QcC",
    "outputId": "8ccbde82-a53f-427c-bafc-a2f1cac996d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sample_submission.csv.zip to /content\n",
      "\r",
      "  0% 0.00/5.13k [00:00<?, ?B/s]\n",
      "100% 5.13k/5.13k [00:00<00:00, 2.17MB/s]\n",
      "Downloading test.zip to /content\n",
      " 91% 78.0M/86.0M [00:00<00:00, 72.8MB/s]\n",
      "100% 86.0M/86.0M [00:01<00:00, 88.6MB/s]\n",
      "Downloading train.zip to /content\n",
      " 99% 1.59G/1.60G [00:21<00:00, 81.1MB/s]\n",
      "100% 1.60G/1.60G [00:21<00:00, 80.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions download -c plant-seedlings-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "lDhmuc7m_0Va",
    "outputId": "a20c3af1-bdc9-45d4-df30-cd6a4ebb803d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all the train.zip files now...\n",
      "Done!\n",
      "Extracting all the test.zip files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile \n",
    "  \n",
    "# file names\n",
    "file_names = [\"train.zip\",\"test.zip\"]\n",
    "  \n",
    "# extraction\n",
    "for file in file_names:\n",
    "    with ZipFile(file, 'r') as zip:  \n",
    "        # extracting all the files \n",
    "        print('Extracting all the {0} files now...'.format(file)) \n",
    "        zip.extractall() \n",
    "        print('Done!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tXw1V-Ls8n2y",
    "outputId": "28649e88-e845-4ddb-9da9-78877440f38a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YN-JzWPf9Ga3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "def readTrainData(trainDir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    # loop over the input images\n",
    "    dirs = os.listdir(trainDir) \n",
    "    # print(dirs)\n",
    "    i=0\n",
    "    for dir in dirs:\n",
    "        absDirPath = os.path.join(trainDir, dir)\n",
    "        images = os.listdir(absDirPath)\n",
    "        Classes=le.fit_transform(dirs)\n",
    "        Cls=Classes[i]\n",
    "        i=i+1\n",
    "        for imageFileName in images:\n",
    "            # load the image, pre-process it, and store it in the data list\n",
    "            imageFullPath = os.path.join(trainDir, dir, imageFileName)\n",
    "            # print(imageFullPath)\n",
    "            img = load_img(imageFullPath)\n",
    "            arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n",
    "            arr = cv2.resize(arr, (128,128)) #Numpy array with shape (HEIGHT, WIDTH,3)\n",
    "            #print(arr.shape) \n",
    "            data.append(arr)\n",
    "            label = Cls\n",
    "            labels.append(label)\n",
    "    return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PxAo6f9CPdJC",
    "outputId": "e07a7eb7-32a7-4fdb-f295-da7e60c5d0c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DATA_FOLDER = \".\"\n",
    "TRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")\n",
    "TRAin_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "ETtN2WbQyAYf",
    "outputId": "da1ff693-cfbc-4281-cff2-e1c62b0aee8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 01:51:26.740725 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0825 01:51:26.793892 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0825 01:51:26.805896 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0825 01:51:26.843087 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0825 01:51:26.846855 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0825 01:51:26.857564 140632606508928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=12)`\n",
      "W0825 01:51:26.971898 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0825 01:51:26.983233 140632606508928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 20)      1520      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 20)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               25600500  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                6012      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 25,633,082\n",
      "Trainable params: 25,633,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 12\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "DEPTH = 3\n",
    "inputShape = (WIDTH, HEIGHT, DEPTH)\n",
    "# initialize number of epochs to train for, initial learning rate and batch size\n",
    "EPOCHS = 15\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "    \n",
    "model = Sequential()\n",
    "    # The CONV  layer will learn 20 convolution filters, each of which are 5×5.\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "    # We then apply a ReLU activation function followed by 2×2 max-pooling in both \n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.001))\n",
    "    # second set of CONV => RELU => POOL layers and a Dropout layer\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.001))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(output_dim=12))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9TiXE9W79r2"
   },
   "outputs": [],
   "source": [
    "X, Y = readTrainData(TRAin_DATA_FOLDER)\n",
    "# Normalisation\n",
    "X = np.array(X, dtype=\"float\") / 255.0\n",
    "Y = np.array(Y)\n",
    "# convert the labels from integers to vectors\n",
    "Y =  to_categorical(Y, num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pHcalp29PB9"
   },
   "outputs": [],
   "source": [
    "(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "a9jV3dQ9BKHp",
    "outputId": "9880bab1-7163-4a18-b53f-e2de1d042064"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 01:54:50.503249 140632606508928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3562 samples, validate on 1188 samples\n",
      "Epoch 1/15\n",
      "3562/3562 [==============================] - 17s 5ms/step - loss: 2.0625 - acc: 0.3175 - val_loss: 1.5907 - val_acc: 0.4209\n",
      "Epoch 2/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 1.2508 - acc: 0.5654 - val_loss: 1.2674 - val_acc: 0.5556\n",
      "Epoch 3/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.9217 - acc: 0.6791 - val_loss: 1.0976 - val_acc: 0.6305\n",
      "Epoch 4/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.7556 - acc: 0.7389 - val_loss: 0.9458 - val_acc: 0.6869\n",
      "Epoch 5/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.5880 - acc: 0.7981 - val_loss: 0.9206 - val_acc: 0.6995\n",
      "Epoch 6/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.4182 - acc: 0.8608 - val_loss: 0.9677 - val_acc: 0.6919\n",
      "Epoch 7/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.3396 - acc: 0.8897 - val_loss: 0.9203 - val_acc: 0.7281\n",
      "Epoch 8/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.2659 - acc: 0.9093 - val_loss: 0.8733 - val_acc: 0.7475\n",
      "Epoch 9/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.2179 - acc: 0.9236 - val_loss: 0.9982 - val_acc: 0.7281\n",
      "Epoch 10/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.1451 - acc: 0.9495 - val_loss: 1.0246 - val_acc: 0.7441\n",
      "Epoch 11/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.0908 - acc: 0.9736 - val_loss: 1.1424 - val_acc: 0.7365\n",
      "Epoch 12/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.0631 - acc: 0.9803 - val_loss: 1.1743 - val_acc: 0.7399\n",
      "Epoch 13/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.0340 - acc: 0.9902 - val_loss: 1.2134 - val_acc: 0.7357\n",
      "Epoch 14/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.0381 - acc: 0.9876 - val_loss: 1.2013 - val_acc: 0.7441\n",
      "Epoch 15/15\n",
      "3562/3562 [==============================] - 10s 3ms/step - loss: 0.0561 - acc: 0.9860 - val_loss: 1.2651 - val_acc: 0.7357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe792624898>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=BS,validation_data=(valX, valY), epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VGNzrIRHCov5",
    "outputId": "4020ddac-3875-44ff-d0ff-0806e7607f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 1s 825us/step\n",
      "Test Accuracy: 0.7356902356902357\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(valX, valY) \n",
    "print('Test Accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "iAib7_XDGm5x",
    "outputId": "91e5fd00-1fad-46b9-f64a-b65e3af10f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "111/111 [==============================] - 15s 132ms/step - loss: 1.4065 - acc: 0.5526 - val_loss: 0.8902 - val_acc: 0.7163\n",
      "Epoch 2/15\n",
      "111/111 [==============================] - 14s 125ms/step - loss: 1.0256 - acc: 0.6451 - val_loss: 0.8116 - val_acc: 0.7407\n",
      "Epoch 3/15\n",
      "111/111 [==============================] - 14s 125ms/step - loss: 0.9518 - acc: 0.6676 - val_loss: 0.6758 - val_acc: 0.7769\n",
      "Epoch 4/15\n",
      "111/111 [==============================] - 14s 124ms/step - loss: 0.8503 - acc: 0.7144 - val_loss: 0.6745 - val_acc: 0.7887\n",
      "Epoch 5/15\n",
      "111/111 [==============================] - 14s 126ms/step - loss: 0.8205 - acc: 0.7226 - val_loss: 0.7072 - val_acc: 0.7668\n",
      "Epoch 6/15\n",
      "111/111 [==============================] - 14s 124ms/step - loss: 0.7576 - acc: 0.7428 - val_loss: 0.6495 - val_acc: 0.7811\n",
      "Epoch 7/15\n",
      "111/111 [==============================] - 14s 126ms/step - loss: 0.7339 - acc: 0.7472 - val_loss: 0.5593 - val_acc: 0.8173\n",
      "Epoch 8/15\n",
      "111/111 [==============================] - 14s 124ms/step - loss: 0.6882 - acc: 0.7635 - val_loss: 0.5895 - val_acc: 0.8072\n",
      "Epoch 9/15\n",
      "111/111 [==============================] - 14s 125ms/step - loss: 0.6765 - acc: 0.7670 - val_loss: 0.5206 - val_acc: 0.8224\n",
      "Epoch 10/15\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6409 - acc: 0.7774 - val_loss: 0.5608 - val_acc: 0.8140\n",
      "Epoch 11/15\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6333 - acc: 0.7848 - val_loss: 0.5328 - val_acc: 0.8199\n",
      "Epoch 12/15\n",
      "111/111 [==============================] - 14s 122ms/step - loss: 0.6128 - acc: 0.7952 - val_loss: 0.4916 - val_acc: 0.8291\n",
      "Epoch 13/15\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 0.5976 - acc: 0.8006 - val_loss: 0.7809 - val_acc: 0.7365\n",
      "Epoch 14/15\n",
      "111/111 [==============================] - 14s 123ms/step - loss: 0.5734 - acc: 0.8003 - val_loss: 0.4987 - val_acc: 0.8375\n",
      "Epoch 15/15\n",
      "111/111 [==============================] - 13s 122ms/step - loss: 0.5424 - acc: 0.8126 - val_loss: 0.4865 - val_acc: 0.8291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe73d5c90b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying Image augumentation for improving the accuracy\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "model.fit_generator(aug.flow(trainX, trainY,batch_size=BS),validation_data=(valX, valY),steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "4hpJQ5teHh_W",
    "outputId": "c88086ed-5753-4f82-b734-0570bc17bf2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 1s 772us/step\n",
      "Test Accuracy: 0.8291245791245792 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.28      0.33        64\n",
      "           1       0.86      0.93      0.89        95\n",
      "           2       0.89      0.93      0.91        85\n",
      "           3       0.92      0.91      0.91       165\n",
      "           4       0.72      0.88      0.79        56\n",
      "           5       0.92      0.84      0.88       122\n",
      "           6       0.76      0.76      0.76       156\n",
      "           7       0.86      0.98      0.92        51\n",
      "           8       0.76      0.92      0.83       126\n",
      "           9       0.78      0.63      0.70        68\n",
      "          10       0.94      0.87      0.90       106\n",
      "          11       0.89      0.84      0.86        94\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1188\n",
      "   macro avg       0.81      0.81      0.81      1188\n",
      "weighted avg       0.83      0.83      0.82      1188\n",
      " samples avg       0.83      0.83      0.83      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_pred_class=model.predict_classes(valX)\n",
    "y_pred=np_utils.to_categorical(y_pred_class,12)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Score=model.evaluate(valX, valY)\n",
    "print('Test Accuracy:',Score[1],'\\n')\n",
    "print(classification_report(valY, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "6yaRf1WMiff6",
    "outputId": "a652e8cf-dfe7-4935-a34c-91285376aa84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlock : 1\n",
      "Black-grass : 0\n",
      "Loose Silky-bent : 6\n",
      "Shepherds Purse : 9\n",
      "Common Chickweed : 3\n",
      "Sugar beet : 11\n",
      "Small-flowered Cranesbill : 10\n",
      "Common wheat : 4\n",
      "Fat Hen : 5\n",
      "Maize : 7\n",
      "Scentless Mayweed : 8\n",
      "Cleavers : 2\n"
     ]
    }
   ],
   "source": [
    "dirs = os.listdir(TRAin_DATA_FOLDER) \n",
    "Classes=le.fit_transform(dirs)\n",
    "for i in range(len(dirs)):\n",
    "  print(dirs[i],':',Classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "PFp4Bk4kg67O",
    "outputId": "e1554b0e-2f12-48bf-82a2-36826cdfc869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "148/148 [==============================] - 19s 130ms/step - loss: 0.5447 - acc: 0.8136 - val_loss: 0.4628 - val_acc: 0.8384\n",
      "Epoch 2/15\n",
      "148/148 [==============================] - 18s 124ms/step - loss: 0.5308 - acc: 0.8177 - val_loss: 0.4115 - val_acc: 0.8577\n",
      "Epoch 3/15\n",
      "148/148 [==============================] - 18s 124ms/step - loss: 0.5246 - acc: 0.8170 - val_loss: 0.3678 - val_acc: 0.8662\n",
      "Epoch 4/15\n",
      "148/148 [==============================] - 18s 124ms/step - loss: 0.4686 - acc: 0.8351 - val_loss: 0.3718 - val_acc: 0.8746\n",
      "Epoch 5/15\n",
      "148/148 [==============================] - 18s 123ms/step - loss: 0.4790 - acc: 0.8321 - val_loss: 0.3477 - val_acc: 0.8805\n",
      "Epoch 6/15\n",
      "148/148 [==============================] - 19s 126ms/step - loss: 0.4650 - acc: 0.8392 - val_loss: 0.3470 - val_acc: 0.8838\n",
      "Epoch 7/15\n",
      "148/148 [==============================] - 19s 126ms/step - loss: 0.4464 - acc: 0.8392 - val_loss: 0.3014 - val_acc: 0.8880\n",
      "Epoch 8/15\n",
      "148/148 [==============================] - 19s 125ms/step - loss: 0.4372 - acc: 0.8469 - val_loss: 0.2933 - val_acc: 0.8948\n",
      "Epoch 9/15\n",
      "148/148 [==============================] - 19s 125ms/step - loss: 0.4138 - acc: 0.8559 - val_loss: 0.3362 - val_acc: 0.8788\n",
      "Epoch 10/15\n",
      "148/148 [==============================] - 19s 125ms/step - loss: 0.4194 - acc: 0.8542 - val_loss: 0.3055 - val_acc: 0.8847\n",
      "Epoch 11/15\n",
      "148/148 [==============================] - 18s 124ms/step - loss: 0.4090 - acc: 0.8600 - val_loss: 0.2858 - val_acc: 0.8906\n",
      "Epoch 12/15\n",
      "148/148 [==============================] - 18s 125ms/step - loss: 0.4015 - acc: 0.8574 - val_loss: 0.2705 - val_acc: 0.9066\n",
      "Epoch 13/15\n",
      "148/148 [==============================] - 18s 125ms/step - loss: 0.3814 - acc: 0.8667 - val_loss: 0.2581 - val_acc: 0.8981\n",
      "Epoch 14/15\n",
      "148/148 [==============================] - 19s 126ms/step - loss: 0.3876 - acc: 0.8623 - val_loss: 0.2624 - val_acc: 0.9057\n",
      "Epoch 15/15\n",
      "148/148 [==============================] - 18s 124ms/step - loss: 0.3751 - acc: 0.8695 - val_loss: 0.2647 - val_acc: 0.9015\n",
      "4750/4750 [==============================] - 3s 690us/step\n",
      "Test Accuracy: 0.9261052630826047 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.42      0.55       263\n",
      "           1       0.97      0.97      0.97       390\n",
      "           2       0.97      0.95      0.96       287\n",
      "           3       0.96      0.97      0.97       611\n",
      "           4       0.95      0.82      0.88       221\n",
      "           5       0.94      0.96      0.95       475\n",
      "           6       0.80      0.97      0.87       654\n",
      "           7       0.99      0.96      0.97       221\n",
      "           8       0.95      0.96      0.96       516\n",
      "           9       0.96      0.87      0.91       231\n",
      "          10       0.95      0.99      0.97       496\n",
      "          11       0.95      0.96      0.95       385\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      4750\n",
      "   macro avg       0.93      0.90      0.91      4750\n",
      "weighted avg       0.93      0.93      0.92      4750\n",
      " samples avg       0.93      0.93      0.93      4750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Train\n",
    "model.fit_generator(aug.flow(X, Y,batch_size=BS),validation_data=(valX, valY),steps_per_epoch=len(X) // BS, epochs=EPOCHS, verbose=1)\n",
    "y_pred_class=model.predict_classes(X)\n",
    "y_pred=np_utils.to_categorical(y_pred_class,12)\n",
    "Score=model.evaluate(X, Y)\n",
    "print('Test Accuracy:',Score[1],'\\n')\n",
    "print(classification_report(Y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Project 1-Computer Vision using CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
